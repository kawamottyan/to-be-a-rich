{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97e51e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#インストール\n",
    "#!pip install selenium\n",
    "#!pip install chromedriver-binary-auto\n",
    "#!pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "495f1fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#スクレイピング\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select,WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "import os\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "770b0ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kawam\\AppData\\Local\\Temp\\ipykernel_30948\\2276666827.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function selenium.webdriver.support.expected_conditions.presence_of_all_elements_located.<locals>._predicate(driver)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "wait = WebDriverWait(driver,10)\n",
    "\n",
    "URL = \"https://db.netkeiba.com/?pid=horse_search_detail\"\n",
    "driver.get(URL)\n",
    "time.sleep(1)\n",
    "wait.until(EC.presence_of_all_elements_located)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29cc9634",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "age = 'none'\n",
    "color = 'chestnut-hair'\n",
    "division = 'none'\n",
    "\n",
    "age_element =driver.find_element(By.NAME,\"under_age\")\n",
    "age_select = Select(age_element)\n",
    "age_select.select_by_value(str(age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48cfcea5-b74c-4d1d-ac45-051c5c819686",
   "metadata": {},
   "outputs": [],
   "source": [
    "#color 1から\n",
    "for i in range(1,2):\n",
    "    terms = driver.find_element(By.ID,\"check_color_0\"+ str(i))\n",
    "    terms.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d6c0dd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#division 0から\n",
    "for i in range(0,1):\n",
    "    terms = driver.find_element(By.ID,\"check_umamark_\"+ str(i))\n",
    "    terms.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5da03a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_element = driver.find_element(By.NAME,'list')\n",
    "list_select = Select(list_element)\n",
    "list_select.select_by_value(\"100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2bd5779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function selenium.webdriver.support.expected_conditions.presence_of_all_elements_located.<locals>._predicate(driver)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# フォームを送信\n",
    "frm = driver.find_element(By.CSS_SELECTOR,\"#db_search_detail_form > form\")\n",
    "frm.submit()\n",
    "time.sleep(5)\n",
    "wait.until(EC.presence_of_all_elements_located)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd03d835",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('text'):\n",
    "    os.makedirs('text')\n",
    "\n",
    "with open(\"text/\"+str(color)+\"-\"+str(division)+\".txt\", mode='w') as f:\n",
    "    while True:\n",
    "        time.sleep(5)\n",
    "        wait.until(EC.presence_of_all_elements_located)\n",
    "        all_rows = driver.find_element(By.CLASS_NAME,'race_table_01').find_elements(By.TAG_NAME,\"tr\")\n",
    "        for row in range(1, len(all_rows)):\n",
    "            race_href=all_rows[row].find_elements(By.TAG_NAME,\"td\")[1].find_element(By.TAG_NAME,\"a\").get_attribute(\"href\")\n",
    "            f.write(race_href+\"\\n\")\n",
    "        try:\n",
    "            target = driver.find_elements(By.LINK_TEXT,\"次\")[0]\n",
    "            driver.execute_script(\"arguments[0].click();\", target) \n",
    "        except IndexError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bf27301",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'cp932' codec can't encode character '\\ufffd' in position 38675: illegal multibyte sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30948\\1329726648.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'cp932' codec can't encode character '\\ufffd' in position 38675: illegal multibyte sequence"
     ]
    }
   ],
   "source": [
    "save_dir = \"html\"+\"/\"+str(color)+\"-\"+str(division)\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "        \n",
    "with open(\"text/\"+str(color)+\"-\"+str(division)+\".txt\", \"r\") as f:\n",
    "    urls = f.read().splitlines()\n",
    "    for url in urls:\n",
    "        list = url.split(\"/\")\n",
    "        horse_id = list[-2]\n",
    "        save_file_path = save_dir+\"/\"+horse_id+'.html'\n",
    "        response = requests.get(url)\n",
    "        response.encoding = response.apparent_encoding\n",
    "        html = response.text\n",
    "        time.sleep(5)\n",
    "        with open(save_file_path, 'w') as file:\n",
    "            file.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37f77aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_data_info_columns=[\n",
    "    'horse_id',\n",
    "    'bday',\n",
    "    'tame_id',\n",
    "    'owner_id',\n",
    "    'producer',\n",
    "    'production area',\n",
    "    'auction price',\n",
    "    'winnings',\n",
    "    'lifetime record',\n",
    "    'wined race title',\n",
    "    'inbreeding-1',\n",
    "    'inbreeding-2',\n",
    "    'father',\n",
    "    'faths father',\n",
    "    'faths mother',\n",
    "    'mother',\n",
    "    'moths father',\n",
    "    'moths mother'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd1458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_horse_data_by_html(horse_id, html):\n",
    "    horse_list = [horse_id]\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    horse_tables = soup.find(\"table\", class_=\"db_prof_table\")\n",
    "    horse_table = horse_tables.findAll(\"td\")\n",
    "    #for i in range(10):\n",
    "    horse_list.append(horse_table[0].get_text())\n",
    "    horse_list.append(horse_table[1].find('a').get('href').split(\"/\")[-2])\n",
    "    horse_list.append(horse_table[2].find('a').get('href').split(\"/\")[-2])\n",
    "    horse_list.append(horse_table[3].find('a').get('href').split(\"/\")[-2])\n",
    "    horse_list.append(horse_table[4].get_text())\n",
    "    horse_list.append(horse_table[5].get_text())\n",
    "    horse_list.append(horse_table[6].get_text())\n",
    "    horse_list.append(horse_table[7].get_text())\n",
    "    horse_list.append(horse_table[8].find('a').get('href').split(\"/\")[-2])\n",
    "    \n",
    "    # horse_table[8]からすべてのリンクのURLの一部を取得する\n",
    "    url_parts = [link.get('href').split(\"/\")[-2] for link in horse_table[9].find_all('a')]\n",
    "\n",
    "    # url_partsの要素数が2未満の場合、残りの要素をNaNで埋める\n",
    "    while len(url_parts) < 2:\n",
    "        url_parts.append(np.nan)\n",
    "\n",
    "    # horse_listにurl_partsを追加する\n",
    "    horse_list.extend(url_parts)\n",
    "    \n",
    "    #horse_list.append(horse_table[9].get_text())\n",
    "    blood_tables = soup.find(\"table\", class_=\"blood_table\")\n",
    "    blood_table = blood_tables.findAll(\"td\")\n",
    "    #for i in range(6):\n",
    "    horse_list.append(blood_table[0].find('a').get('href').split(\"/\")[-2])\n",
    "    horse_list.append(blood_table[1].find('a').get('href').split(\"/\")[-2])\n",
    "    horse_list.append(blood_table[2].find('a').get('href').split(\"/\")[-2])\n",
    "    horse_list.append(blood_table[3].find('a').get('href').split(\"/\")[-2])\n",
    "    horse_list.append(blood_table[4].find('a').get('href').split(\"/\")[-2])\n",
    "    horse_list.append(blood_table[5].find('a').get('href').split(\"/\")[-2])\n",
    "    return horse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9183e48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_DIR = \"csv\"\n",
    "if not os.path.isdir(CSV_DIR):\n",
    "    os.makedirs(CSV_DIR)\n",
    "horse_info_csv = CSV_DIR+\"/horse-info-\"+str(color)+\"-\"+str(division)+\".csv\"\n",
    "\n",
    "horse_df = pd.DataFrame(columns=horse_data_info_columns)\n",
    "\n",
    "html_dir = \"html\"+\"/\"+str(color)+\"-\"+str(division)\n",
    "if os.path.isdir(html_dir):\n",
    "    file_list = os.listdir(html_dir)\n",
    "    for file_name in file_list:\n",
    "        with open(html_dir+\"/\"+file_name, \"r\") as f:\n",
    "            html = f.read()\n",
    "            list = file_name.split(\".\")\n",
    "            horse_id = list[-2]\n",
    "            horse_list = get_horse_data_by_html(horse_id, html) \n",
    "            horse_se = pd.Series(horse_list, index=horse_df.columns)\n",
    "            horse_df = pd.concat([horse_df, horse_se.to_frame().T], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc79bd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_df.to_csv(horse_race_csv, header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fca794",
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
